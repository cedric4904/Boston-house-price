---
title: "Project Boston"
author: "Nam Nguyen"
date: "2025-04-13"
output:
  html_document:
    df_print: paged
---

#Import the dataset

-- Import the dataset

```{r message=FALSE, warning=FALSE, include=FALSE, results=FALSE}
setwd("E:\\Uni Study\\Project\\Bostonhouse")
library(readr)
housing <- read_table("housing.csv", col_names = FALSE)
View(housing)
```

-- Name the column

```{r}
colnames(housing) <- c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',
                                              'PTRATIO', 'B', 'LSTAT', 'MEDV')
head(housing)
```

-- Adding labels

```{r}
library(labelled)

# Set variable labels for the housing dataset
var_label(housing$CRIM) <- "per capita crime rate by town"
var_label(housing$ZN) <- "proportion of residential land zoned for lots over 25,000 sq.ft"
var_label(housing$INDUS) <- "proportion of non-retail business acres per town"
var_label(housing$CHAS) <- "Charles River dummy variable (1 if tract bounds river; 0 otherwise)"
var_label(housing$NOX) <- "nitric oxides concentration (parts per 10 million)"
var_label(housing$RM) <- "average number of rooms per dwelling"
var_label(housing$AGE) <- "proportion of owner-occupied units built prior to 1940"
var_label(housing$DIS) <- "weighted distances to five Boston employment centres"
var_label(housing$RAD) <- "index of accessibility to radial highways"
var_label(housing$TAX) <- "full-value property-tax rate per $10,000"
var_label(housing$PTRATIO) <- "pupil-teacher ratio by town"
var_label(housing$B) <- "1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town"
var_label(housing$LSTAT) <- "% lower status of the population"
var_label(housing$MEDV) <- "Median value of owner-occupied homes in $1000's"
var_label(housing)
```

--Check the variable type

```{r}
str(housing)
```

=\> All **numeric**

-   Check for missing value:

```{r}
colSums(is.na(housing))
```

=\> **No missing value**

#Descriptive stats on the data

```{r}
summary(housing)
par(mfrow = c(4, 4), mar = c(4, 4, 2, 1))
for (col in colnames(housing)) {
  hist(housing[[col]], main = paste("Histogram of", col), xlab = col, col = "skyblue", border = "black")
}
```

In 1970:

About the housing price, the distribution of MEDV is right-skewed, with the majority of properties concentrated in the \$20,000–\$30,000 range. Besides, most houses in Boston were spacious as the RM histogram lied primarily in 6-7 rooms. The house age histogram, on the other hand, was left-skewed, which means that the houses in Boston, for the most part, were old.

About the infrastructure, the accessibility to the centered areas of Boston were well-developed. However, that to radial highways is in the opposite condition

Some other features worth noticing is that CRIM and ZN are also lied on the left side of the graph, which indicates that the metropolitan areas in Boston were not so well-developed, and the crime rate were low.

-- Compare the median value of price by position of Charles

```{r}
library(ggplot2)
gg1 <- ggplot(housing, aes(factor(CHAS), MEDV)) +
  geom_boxplot() +
  xlab("If tract bounds river") +
  ylab("Median value of house price") +
  ggtitle("Compare median value of price by position of Charles River")
gg1 <- gg1 + theme(plot.title = element_text(hjust = 0.5, margin = margin(b = 20)))
gg1 <- gg1 + scale_x_discrete(labels = c("0" = "No", "1" = "Yes"))
print(gg1)
```

-- Compare the proportion of of non-retail by position of Charles

```{r}
gg <- ggplot(housing, aes(factor(CHAS), INDUS)) +
      geom_boxplot() +
      xlab("If tract bounds river") +
      ylab("Proportion of non-retail business") +
      ggtitle("Comparision of non-retail by postion of Charles River")
gg <- gg + theme(plot.title = element_text(hjust = 0.5, margin = margin(b = 20)))
gg <- gg + scale_x_discrete(labels = c("0" = "No", "1" = "Yes"))
print(gg)
```

Overall, the level of urbanization in streets located by the Charles River is much higher than those that are not The average proportion of non-retail businesses in areas not adjacent to the river is 8 per town, while in other areas, it is approximately 15 businesses per town. Therefore, the average median value of housing prices in streets near the Charles River seems to be higher, at about \$15,000.

-- Compare the age group of house

```{r}
library(dplyr)
# Count the unique value in AGE
age_table <- table(housing$AGE)
# Convert the table to a data frame and sort to get the top 10 most frequent ages
top_10_age <- as.data.frame(sort(age_table, decreasing = TRUE)[1:10])
#Change the name of column in table
colnames(top_10_age) <- c("AGE", "Frequency")
# Create a pie chart on age group
# Cut the age into 5 different groups
housing$age_group <- cut(housing$AGE, breaks = c(0, 20, 40, 60, 80, 100),
                         labels = c("1-20", "21-40", "41-60", "61-80", "81-100"), include.lowest = TRUE)
result <- housing %>%
  group_by(age_group) %>%
  summarize(avg_price = mean(MEDV))
print(result)
```

In Boston, most houses in Boston are old and dated back from 18th and 19th century. However, older houses in Boston often command lower prices compared to more recently constructed properties. =\> the age of a house can inversely correlate with its value in Boston’s real estate market

```{r}
# Count the unique value in age group
age_counts <- table(housing$age_group)
# Convert into dataframe
age_counts_df <- as.data.frame(age_counts)
colnames(age_counts_df) <- c("Age_Group", "Frequency")
#Pie chart 
ggplot(age_counts_df, aes(x = "", y = Frequency, fill = Age_Group, label = Frequency)) +
  geom_bar(stat = "identity", width = 1) +
  geom_label(position = position_stack(vjust = 0.5), color = "black") +
  coord_polar("y", start = 0) +
  ggtitle("Distribution of houses in Age Groups") +
  scale_fill_manual(values = c("#CF6969", "#F1B9A6", "#FFD9C8", "#FCFBF5", "#F8B6C7", "#4E6134")) +
  theme_minimal() +
  theme_void()
```

-- Correlation

```{r}
#Correlation test 
selected_data <- housing[, c("CRIM", "ZN", "INDUS","NOX","RM","AGE","DIS","RAD","TAX","PTRATIO","B","LSTAT","MEDV")]
correlation_matrix <- cor(selected_data, method = "spearman")
correlation_matrix
```

Factors such as **residential land proportion, number of rooms, distance to centers, and racial proportion** positively correlate with prices, while **others** show a negative trend.

#Building the Regression model

-- build the mlr model

```{r}
lm <- lm(MEDV ~ CRIM +ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT, data = housing)
summary(lm)
```

All given variables explain 74.06% the change of house price in Boston. =\> Except for Indus, AGE, all variables affected the price of house

-- OLS assumption test

```{r}
par(mfrow=c(2,2))
plot(lm)
```

it seems like the model has violated normality, use BP test to ensure. the residual does not follow linear

-- Homoscedasticity test

```{r}
library(lmtest)
bptest(lm)
```

not violated

-- Durbin-watson test for independence of errors

```{r}
library(car)
dw_result <- durbinWatsonTest(lm)
dw_result
```

=\> Violated

-- Normality test of residuals:

```{r}
residuals <- residuals(lm)
ks_result <- ks.test(residuals, "pnorm")
print(ks_result) 
```

=\> normality test not violated

**only violated linearity**

-- Multicollinearity

```{r}
vif_values <- vif(lm)
vif_values
```

all \< 10, so no Multicollinearity violated

-- compare the beta coef

```{r}
library(lm.beta)
beta_coefs <- lm.beta(lm)
beta_coefs
```

compare the absolute value (Except for Indus, AGE) =\> **LSTAT, DIS, RM** seem to have the biggest effect on the house price in Boston (1970)

#KNN Regression

Since the dataset is all numeric, so I used the Knn regression

-- data normalization

```{r}
library(caret)
library(dplyr)
housing1 <- preProcess(housing, method = "center", "scale")
housingfinal <- predict(housing1, housing)
```

-- Divide the dataset into training set and test set

```{r}
set.seed(123)
training <- createDataPartition(housing$MEDV, p=0.8, list = FALSE)
training_set <- slice(housingfinal, training)
test_set <- slice(housingfinal, -training)
```

-- Train the knn model

```{r}
best_knn <- train(MEDV~CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B +LSTAT, training_set, #Predict the med value from other variables, method = Cross-validation
method="knn",
na.action = na.omit,
tuneLength = 10)
```

-- Choose the best knn

```{r}
best_knn
plot(best_knn)
best_knn$bestTune
```

=\> **K =  5 is the best**

```{r}
predicted.classes <- predict(best_knn, test_set)
y_test <- test_set$MEDV
data.frame(y_test, predicted.classes)
```


```{r}
mse = mean((y_test - predicted.classes)^2)
mae = caret::MAE(y_test, predicted.classes)
rmse = caret::RMSE(y_test, predicted.classes)
cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)

```

```{r}
plot(y_test, col = "red", type = "l") # Draw y_test as line
lines(predicted.classes, col = "blue") # Draw predicted.classes
legend("topright", legend = c("original-medv", "predicted-medv"), fill = c("red", "blue"))
grid()
```

**k = 5 is moderately accurate**

*Note: This file I used just for practicing statistical methods on Rstudio. So, the model is for reference purpose only and based on the train and test set every individual has. For more accurate method, we can use the loop fucntion.*
